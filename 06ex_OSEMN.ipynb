{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "import csv\n",
    "import json\n",
    "import struct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1\\. **Text files**\n",
    "\n",
    "Perform the following operations on plain `txt` files:\n",
    "\n",
    "+ create a list of integrer numbers and then save it to a text file named `data_int.txt`. Run the `cat` command to print the content of the file.\n",
    "+ create a matrix of 5x5 floats and then save it to a text file named `data_float.txt`. Use the `cat` command to print the content of the file.\n",
    "+ load the `txt` file of the previous point and convert it to a `csv` file by hand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data_float.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/5v/lrjj2scd07924486ywqbnbcm0000gn/T/ipykernel_79755/201958264.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;31m#ex_1_2()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m \u001b[0mload_txt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/var/folders/5v/lrjj2scd07924486ywqbnbcm0000gn/T/ipykernel_79755/201958264.py\u001b[0m in \u001b[0;36mload_txt\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mload_txt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mtext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34mr'data_float.txt'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mread_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;31m#Loading part\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mread_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m             \u001b[0mtext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data_float.txt'"
     ]
    }
   ],
   "source": [
    "def ex_1_1():\n",
    "    a=random.randint(1,10)\n",
    "    lista=[]\n",
    "    for values in range(a):\n",
    "        lista.append(random.randint(1,10))\n",
    "    file = open('data_int.txt', 'w')\n",
    "    file.write(str(lista))\n",
    "    file.close()\n",
    "    os.system('cat data_int.txt')\n",
    "    \n",
    "def ex_1_2():\n",
    "    a=np.matrix('1.1 2.1 3.1 4.1 5.1;1.1 2.1 3.1 4.1 5.1;1.1 2.1 3.1 4.1 5.1;1.1 2.1 3.1 4.1 5.1;1.1 2.1 3.1 4.1 5.1')\n",
    "    np.savetxt(\"data_float.txt\", a)\n",
    "    os.system('cat data_float.txt')\n",
    "\n",
    "def load_txt():  \n",
    "    text=\"\"\n",
    "    with open (r'data_float.txt') as read_file:#Loading part\n",
    "        for line in read_file:\n",
    "            text=text+line+\"\\n\"\n",
    "            \n",
    "    with open('data1_float.csv', 'w') as data1:\n",
    "        data1.write(text)\n",
    "        #read_file.to_csv (r'data1_float.csv') \n",
    "        \n",
    "\n",
    "#ex_1_2()\n",
    "load_txt()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2\\. **JSON files**\n",
    "\n",
    "Load the file *user_data.json*, which can be found at:\n",
    "\n",
    "- https://www.dropbox.com/s/sz5klcdpckc39hd/user_data.json\n",
    "\n",
    "and filter the data by the \"CreditCardType\" when it equals to \"American Express\". Than save the data to a new CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!wget https://www.dropbox.com/s/sz5klcdpckc39hd/user_data.json\n",
    "    \n",
    "#input_dict = json.loads('user_data.json')\n",
    "with open('user_data.json', 'r') as f:\n",
    "    data = json.load(f)\n",
    "output_dict = [x for x in data if x['CreditCardType'] == 'American Express']\n",
    "output_json = json.dumps(output_dict)\n",
    "\n",
    "df = pd.read_json (output_json)\n",
    "df.to_csv (r'user1.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3\\. **CSV files with Pandas**\n",
    "\n",
    "Load the file from this url:\n",
    "\n",
    "- https://www.dropbox.com/s/kgshemfgk22iy79/mushrooms_categorized.csv\n",
    "\n",
    "with Pandas. \n",
    "\n",
    "+ explore and print the DataFrame\n",
    "+ calculate, using `groupby()`, the average value of each feature, separately for each class\n",
    "+ save the file in a JSON format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!wget https://www.dropbox.com/s/kgshemfgk22iy79/mushrooms_categorized.csv\n",
    "df = pd.read_csv(r'mushrooms_categorized.csv')\n",
    "a=df.groupby(by=\"class\").mean()\n",
    "a.to_json(r'mushrooms.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4\\. **Reading the credit card numbers**\n",
    "\n",
    "Get the binary file named *credit_card.dat* from this address:\n",
    "\n",
    "- https://www.dropbox.com/s/8m0syw2tkul3dap/credit_card.dat\n",
    "\n",
    "and convert the data into the real credit card number, knowing that:\n",
    "- each line corresponds to a credit card number, which consists of 16 characters (which are numbers in the 0-9 range) divided in 4 blocks, with a whitespace between each block\n",
    "- each character is written using a 6 bit binary representation (including the whitespace)\n",
    "- the final 4 bits of each line are a padding used to determine the end of the line, and can be ignored\n",
    "\n",
    "*Hint*: convert the binary numbers to the decimal representation first, and then use the `chr()` function to convert the latter to a char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!wget https://www.dropbox.com/s/8m0syw2tkul3dap/credit_card.dat\n",
    "\n",
    "datContent = [i.strip().split() for i in open(\"credit_card.dat\").readlines()]\n",
    "\n",
    "\n",
    "with open(\"cc.csv\", \"w\") as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerows(datContent)\n",
    "    \n",
    "block=[]\n",
    "\n",
    "with open(\"cc.csv\", \"r\") as f:\n",
    "    for lines in f:\n",
    "        if len(lines)>4:\n",
    "            block.append(lines[0:24])\n",
    "            block.append(lines[30:54])\n",
    "            block.append(lines[60:84])\n",
    "            block.append(lines[90:114])\n",
    "            value=\"\"\n",
    "            for blocks in block:\n",
    "                for i in range(4):\n",
    "                    value=value+str(int(blocks[6*i+2:6*i+6],2))\n",
    "            block=[]\n",
    "            print(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5\\. **Write data to a binary file**\n",
    "\n",
    "a) Start from the `data/data_000637.txt` file that we have used during the previous lectures, and convert it to a binary file according to the format defined below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "Image(\"data_format.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Hints*:\n",
    "- Read the first 10 lines using Pandas\n",
    "- Iterate over the DataFrame rows\n",
    "- For every row, ``pack'' the values (features) into a single 64-bit word, according to the format specified above. Use bit-wise shifts and operators to do so.\n",
    "- Write each 64-bit word to a binary file. You can use `struct` in this way:\n",
    "```\n",
    "binary_file.write( struct.pack('<q', word) )\n",
    "```\n",
    "where `word` is the 64-bit word.\n",
    "- Close the file after completing the loop.\n",
    "\n",
    "b) Check that the binary file is correctly written by reading it with the code used in the lecture `06_OSEMN.ipynb`, and verify that the content of the `txt` and binary files is consistent.\n",
    "\n",
    "c) What is the difference of the size on disk between equivalent `txt` and binary files?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = \"data_000637.txt\" \n",
    "A=10\n",
    "df_c = pd.read_csv(file_name)\n",
    "\n",
    "#FASE DI SCRITTURA\n",
    "with open('data_000637_to_binary.dat', 'wb') as binary_file:    \n",
    "    \n",
    "    for index, row in df_c.iterrows():\n",
    "        word = 0\n",
    "        word = (row['HEAD'] << 62) | word\n",
    "        word = (row['FPGA'] << 58) | word\n",
    "        word = (row['TDC_CHANNEL'] << 49) | word\n",
    "        word = (row['ORBIT_CNT'] << 17) | word\n",
    "        word = (row['BX_COUNTER'] << 5 ) | word\n",
    "        word = (row['TDC_MEAS'] << 0 ) | word\n",
    "        binary_file.write(struct.pack('<q', word))\n",
    "        \n",
    "data = {}\n",
    "columns = ['HEAD', 'FPGA', 'CHANNEL', 'ORBIT_CNT', 'BX_CNT', 'TDC_MEAS']\n",
    "df = pd.DataFrame({}, columns=columns)\n",
    "\n",
    "#FASE DI LETTURA PER IL CHECK\n",
    "with open('data_000637_to_binary.dat', 'rb') as file:\n",
    "    file_content = file.read()\n",
    "    cnt = 0\n",
    "    word_size = 8\n",
    "    \n",
    "    for i in range(0, len(file_content), word_size):\n",
    "        \n",
    "        cnt= cnt+1\n",
    "        word = struct.unpack('<q', file_content[i : i + word_size])[0] # get an 8-byte word\n",
    "        head     = (word >> 62) & 0x3\n",
    "        fpga     = (word >> 58) & 0xF\n",
    "        tdc_chan = (word >> 49) & 0x1FF\n",
    "        orb_cnt  = (word >> 17) & 0xFFFFFFFF\n",
    "        bx       = (word >> 5 ) & 0xFFF\n",
    "        tdc_meas = (word >> 0 ) & 0x1F\n",
    "        entry = {'HEAD' : head, 'FPGA' : fpga, 'CHANNEL' : tdc_chan, 'ORBIT_CNT' : orb_cnt, 'BX_CNT' : bx, 'TDC_MEAS' : tdc_meas}\n",
    "        df = df.append(entry, ignore_index=True)\n",
    "        if cnt > 10: \n",
    "            break\n",
    "      \n",
    "print(df)\n",
    "print(df_c)\n",
    "\n",
    "#La memorizzazione del binario è approssimativamente 1/3 del txt originale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
